{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "source": [
    "G=nx.read_edgelist('datasets/edgelist.txt', delimiter=',',create_using=nx.Graph(),nodetype=int)\n",
    "nodes=list(G.nodes())\n",
    "n=G.number_of_nodes()\n",
    "m=G.number_of_edges()\n",
    "\n",
    "print('Number of nodes:', n)\n",
    "\n",
    "print('Number of edges:', m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts=dict()\n",
    "with open('datasets/abstracts.txt', 'r',encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        node,abstract=line.split('|--|')\n",
    "        abstracts[int(node)]=abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_x(number_of_edges,list_of_features,mypath):\n",
    "    mypath=mypath\n",
    "    number_of_features=len(list_of_features)\n",
    "    print(\"number_of_edges:\",number_of_edges)\n",
    "    x=np.zeros((2*number_of_edges,number_of_features))\n",
    "    for idx,feature in enumerate(list_of_features):\n",
    "        print(\"loading column {} with feature {}\".format(idx,feature))\n",
    "        x[:,idx]=np.genfromtxt(mypath+feature,delimiter=',')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "def get_feature_files(mypath):\n",
    "    mypath=mypath\n",
    "    features_to_include=[feature for feature in listdir(mypath)]\n",
    "    print(\"included features are: \",features_to_include)\n",
    "    return features_to_include\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included features are:  ['adamic_adar_index.csv', 'common_elements_in_abstracts.csv', 'difference_of_abstracts_len.csv', 'jaccard_coef.csv', 'preferential_attachment.csv', 'resource_allocation_index.csv', 'sum_of_abstracts_len.csv']\n",
      "number_of_edges: 1091955\n",
      "loading column 0 with feature adamic_adar_index.csv\n",
      "loading column 1 with feature common_elements_in_abstracts.csv\n",
      "loading column 2 with feature difference_of_abstracts_len.csv\n",
      "loading column 3 with feature jaccard_coef.csv\n",
      "loading column 4 with feature preferential_attachment.csv\n",
      "loading column 5 with feature resource_allocation_index.csv\n",
      "loading column 6 with feature sum_of_abstracts_len.csv\n"
     ]
    }
   ],
   "source": [
    "mypath='datasets/features_train/'\n",
    "X_train=initialize_x(m,get_feature_files(mypath),mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091955\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da22d4198b655ef0960ccd2ab85141aaa05c0c035eb04e9505cdd8240da58ecf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
