{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bd7e7b",
   "metadata": {},
   "source": [
    "# Link prediction project for paper citations\n",
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d9cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import random as rand\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import savetxt\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4f6f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodes  edges\n",
      "0      0      1\n",
      "1      0      2\n",
      "2      1      3\n",
      "3      1      5\n",
      "4      1      6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "dataset = pd.read_csv('datasets/edgelist.txt', sep = ',' ,header = None)\n",
    "\n",
    "\n",
    "# add names to columns for easier manipulation of data\n",
    "dataset.columns = ['nodes','edges']\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "# check for nan values\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d514723",
   "metadata": {},
   "source": [
    "### Graph creation and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65846895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Graph = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "\n",
    "for x in dataset['nodes']:\n",
    "    Graph.add_node(x)\n",
    "\n",
    "# add edges\n",
    "\n",
    "for x,y in dataset.itertuples(index = False):\n",
    "    Graph.add_edge(x,y)\n",
    "    \n",
    "    \n",
    "\n",
    "# creation of sub graph for plotting \n",
    "\n",
    "subset_data = pd.DataFrame(columns = ['nodes','edges'])\n",
    "\n",
    "subset_data = dataset.head(300)\n",
    "\n",
    "subG = nx.Graph()\n",
    "\n",
    "for x in subset_data['nodes']:\n",
    "    subG.add_node(x)\n",
    "    \n",
    "for x,y in subset_data.itertuples(index = False):\n",
    "    subG.add_edge(x,y)\n",
    "    \n",
    "# plot graph\n",
    "\n",
    "nx.draw(subG)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda34995",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbe8209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays created successfully.\n",
      "12\n",
      "Author graph created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ng_emb = n2v(\\n  Graph,\\n  dimensions=16\\n)\\n    \\nmdl = g_emb.fit(\\n    vector_size = 16,\\n    window = 1,\\n    min_count = 1,\\n    batch_words = 4\\n)\\n\\ninput_node = '1'\\nsim = mdl.wv.most_similar(input_node, topn = 10)\\nprint(sim)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Graph.number_of_edges()\n",
    "nodeCount = Graph.number_of_nodes()\n",
    "n = 18 # number of features\n",
    "\n",
    "X_train = np.zeros((2*m,n))\n",
    "y_train = np.zeros(2*m)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(0,m):\n",
    "    X_train[i,0] = Graph.degree[dataset['nodes'][i]] # degree of first node\n",
    "    X_train[i,1] = Graph.degree[dataset['edges'][i]] # degree of second node\n",
    "    X_train[i,2] = X[i,0] + X[i,1] # sum of these degrees\n",
    "\n",
    "\n",
    "for i in range(m,2*m): # we take all unconnected pairs for negative sample \n",
    "    X_train[i,0] = 138499 - X[i-m,0] # Graph.degree[dataset['nodes'][rand.randint(0,m-1)]]\n",
    "    X_train[i,1] = 138499 - X[i-m,1] # Graph.degree[dataset['edges'][rand.randint(0,m-1)]]\n",
    "    X_train[i,2] = X[i,0] + X[i,1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Read the abstract of each paper\n",
    "\n",
    "abstracts = dict()\n",
    "with open('datasets/abstracts.txt', 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        node, abstract = line.split('|--|')\n",
    "        abstracts[int(node)] = abstract\n",
    "        \n",
    "for node in abstracts:\n",
    "    abstracts[node] = set(abstracts[node].split())\n",
    "\n",
    "# Read the authors of each paper\n",
    "\n",
    "authors = dict()\n",
    "with open('datasets/authors.txt', 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        node, author = line.split('|--|')\n",
    "        authors[int(node)] = author        \n",
    "        \n",
    "for node in authors:\n",
    "    authors[node] = authors[node].strip(\"\\n\")\n",
    "    #authors[node] = authors[node].replace(',',' ')\n",
    "    authors[node] = set(authors[node].split(\",\"))\n",
    "    \n",
    "print(\"Arrays created successfully.\")\n",
    "\n",
    "# Author graph creation\n",
    "\n",
    "authorGraph = nx.Graph()\n",
    "\n",
    "\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    result = authors[edge[0]].intersection(authors[edge[1]])\n",
    "    \n",
    "    # for word in result: just in case\n",
    "    for word3 in authors[edge[1]]:\n",
    "        authorGraph.add_node(word3)\n",
    "    \n",
    "    for word in authors[edge[0]]:\n",
    "        authorGraph.add_node(word)\n",
    "        if result:\n",
    "            for word2 in authors[edge[1]]:\n",
    "                if word == word2:\n",
    "                    continue\n",
    "                else:\n",
    "                    authorGraph.add_edge(word,word2)\n",
    "                   \n",
    "\n",
    "    \n",
    "        \n",
    "print(authorGraph.degree['Jian-Xun Peng'])\n",
    "\n",
    "print(\"Author graph created successfully.\")\n",
    "\n",
    "\n",
    "authorDeg = np.zeros((m,2))\n",
    "deg0 = 0\n",
    "deg1 = 0\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    for word in authors[edge[0]]:\n",
    "        deg0 = authorGraph.degree[word]\n",
    "        authorDeg[i,0] = deg0\n",
    "    for word2 in authors[edge[1]]:\n",
    "        deg1 = authorGraph.degree[word2]\n",
    "        authorDeg[i,1] = deg1\n",
    "    deg0 = 0\n",
    "    deg1 = 0\n",
    "\n",
    "\"\"\"\n",
    "g_emb = n2v(\n",
    "  Graph,\n",
    "  dimensions=16\n",
    ")\n",
    "    \n",
    "mdl = g_emb.fit(\n",
    "    vector_size = 16,\n",
    "    window = 1,\n",
    "    min_count = 1,\n",
    "    batch_words = 4\n",
    ")\n",
    "\n",
    "input_node = '1'\n",
    "sim = mdl.wv.most_similar(input_node, topn = 10)\n",
    "print(sim)\n",
    "\"\"\"    \n",
    "    \n",
    "#for i,edge in enumerate(authorGraph.edges()):\n",
    "    #authorDeg.append(authorGraph.degree[i])\n",
    "    \n",
    "# node2vec testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f299e",
   "metadata": {},
   "source": [
    "## Helpful functions for creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1fe0db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready.\n"
     ]
    }
   ],
   "source": [
    "# Initialize x_train\n",
    "\n",
    "def initialize_x_train(number_of_edges,list_of_features,mypath):\n",
    "    mypath=mypath\n",
    "    number_of_features=len(list_of_features)\n",
    "    print(\"number_of_edges:\",number_of_edges)\n",
    "    #mul by 2 for the training matrix\n",
    "    x=np.zeros((2*number_of_edges,number_of_features))\n",
    "    for idx,feature in enumerate(list_of_features):\n",
    "        print(\"loading column {} with feature {}\".format(idx,feature))\n",
    "        x[:,idx]=np.genfromtxt(mypath+feature,delimiter=',')\n",
    "    return x\n",
    "\n",
    "# Initialize x_test\n",
    "\n",
    "def initialize_x_test(number_of_edges,list_of_features,mypath):\n",
    "    mypath=mypath\n",
    "    number_of_features=len(list_of_features)\n",
    "    print(\"number_of_edges:\",number_of_edges)\n",
    "    #mul by 1 for the training matrix\n",
    "    x=np.zeros((number_of_edges,number_of_features))\n",
    "    for idx,feature in enumerate(list_of_features):\n",
    "        print(\"loading column {} with feature {}\".format(idx,feature))\n",
    "        x[:,idx]=np.genfromtxt(mypath+feature,delimiter=',')\n",
    "    return x\n",
    "\n",
    "# get feature files for debugging purposes\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "def get_feature_files(mypath):\n",
    "    mypath=mypath\n",
    "    features_to_include=[feature for feature in listdir(mypath)]\n",
    "    print(\"included features are: \",features_to_include)\n",
    "    return features_to_include\n",
    "\n",
    "print(\"Functions ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec36c38",
   "metadata": {},
   "source": [
    "## Doc2vec testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95032080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2vec done.\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec testing\n",
    "\n",
    "documents = [TaggedDocument(abstracts[node], [node]) for node in abstracts]\n",
    "model2 = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "print(\"Doc2vec done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdf3254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save done.\n"
     ]
    }
   ],
   "source": [
    "# doc2vec save\n",
    "fname = get_tmpfile(\"doc2vec_model\")\n",
    "\n",
    "model2.save(fname)\n",
    "print(\"Save done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6953a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23140/3125268539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# doc2vec load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdocmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Load successful.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fname' is not defined"
     ]
    }
   ],
   "source": [
    "# doc2vec load\n",
    "\n",
    "docmodel = Doc2Vec.load(fname)\n",
    "print(\"Load successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "795e6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docarray filled.\n",
      "Testing docarray done\n"
     ]
    }
   ],
   "source": [
    "docArray = np.zeros(2*m)\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    docArray[i] = spatial.distance.cosine(docmodel.dv[edge[0]], docmodel.dv[edge[1]])\n",
    "    \n",
    "print(\"docarray filled.\")\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    \n",
    "    n1 = rand.randint(0, nodeCount-1)\n",
    "    n2 = rand.randint(0, nodeCount-1)\n",
    "    docArray[m+i] = spatial.distance.cosine(docmodel.dv[n1], docmodel.dv[n2])\n",
    "    \n",
    "node_pairs = list()\n",
    "\n",
    "with open('datasets/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "docArrayTest = np.zeros(len(node_pairs))\n",
    "\n",
    "for i,node_pair in enumerate(node_pairs):\n",
    "    docArrayTest[i] = spatial.distance.cosine(docmodel.dv[node_pair[0]], docmodel.dv[node_pair[1]]) \n",
    "\n",
    "print(\"Testing docarray done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c14ed59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2vec csvs created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#doc2vec train\n",
    "savetxt('datasets/features_train/doc2vec.csv',docArray[:],delimiter=',')\n",
    "\n",
    "#doc2vec test\n",
    "savetxt('datasets/features_test/doc2vec_test.csv',docArrayTest[:],delimiter=',')\n",
    "print(\"Doc2vec csvs created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880308f",
   "metadata": {},
   "source": [
    "## Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "absSet = abstracts.values()\n",
    "#word2vec\n",
    "model1 = Word2Vec(absSet, vector_size=100, window=5, min_count=1, workers=-1)\n",
    "model1.save(\"word2vec.model\")\n",
    "print(\"done save!\")\n",
    "model1 = Word2Vec.load(\"word2vec.model\")\n",
    "model1.train(absSet, total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ef462",
   "metadata": {},
   "source": [
    "## word2vec feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec.load(\"word2vec.model\")\n",
    "print(\"wordtovec done!\")\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    print(i)\n",
    "    if len(abstracts[edge[0]]) == 0 or len(abstracts[edge[1]]) == 0:\n",
    "        X_train[i,16] = 0\n",
    "    \n",
    "    else:\n",
    "        X_train[i,16] = model1.wv.n_similarity(abstracts[edge[0]],abstracts[edge[1]])\n",
    "        \n",
    "        \n",
    "    \n",
    "    n1 = rand.randint(0, nodeCount-1)\n",
    "    n2 = rand.randint(0, nodeCount-1)\n",
    "     \n",
    "    \n",
    "    if len(abstracts[n1]) == 0 or len(abstracts[n2]) == 0:\n",
    "        X_train[m+i,16] = 0\n",
    "        \n",
    "    else:\n",
    "        X_train[m+i,16] = model1.wv.n_similarity(abstracts[n1],abstracts[n2])\n",
    "        \n",
    "    \n",
    "\n",
    "print(\"DONE 1\")\n",
    "\n",
    "print(\"DONE 2\")    \n",
    "    \n",
    "node_pairs = list()\n",
    "\n",
    "with open('datasets/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "        \n",
    "\n",
    "X_test = np.zeros((len(node_pairs), n))\n",
    "print(len(node_pairs))\n",
    "\n",
    "for i,node_pair in enumerate(node_pairs):\n",
    "    print(i)\n",
    "    if len(abstracts[node_pair[0]]) == 0 or len(abstracts[node_pair[1]]) == 0:\n",
    "        X_test[i,16] = 0\n",
    "        \n",
    "    else: \n",
    "        X_test[i,16] = model1.wv.n_similarity(abstracts[node_pair[0]],abstracts[node_pair[1]])\n",
    "        \n",
    "    \n",
    "print(\"DONE 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33b8c1",
   "metadata": {},
   "source": [
    "## word2vec feature saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e189a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train\n",
    "np.savetxt(\"word2vec_train.csv\",X_train[:,16],delimiter=',')\n",
    "\n",
    "#save test\n",
    "np.savetxt(\"word2vec_test.csv\",X_test[:,16],delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dcf03",
   "metadata": {},
   "source": [
    "## Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbacd915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included features are:  ['abs_degree_difference.csv', 'common_elements_in_abstracts.csv', 'difference_of_abstracts_len.csv', 'doc2vec.csv', 'Graph_degree_sum.csv', 'sum_of_abstracts_len.csv', 'word2vec_train.csv']\n",
      "number_of_edges: 1091955\n",
      "loading column 0 with feature abs_degree_difference.csv\n",
      "loading column 1 with feature common_elements_in_abstracts.csv\n",
      "loading column 2 with feature difference_of_abstracts_len.csv\n",
      "loading column 3 with feature doc2vec.csv\n",
      "loading column 4 with feature Graph_degree_sum.csv\n",
      "loading column 5 with feature sum_of_abstracts_len.csv\n",
      "loading column 6 with feature word2vec_train.csv\n",
      "included features are:  ['abs_degree_difference_test.csv', 'common_elements_in_abstracts_test.csv', 'difference_of_abstracts_test.csv', 'doc2vec_test.csv', 'Graph_degree_sum_test.csv', 'sum_of_abstracts_len_test.csv', 'word2vec_test.csv']\n",
      "number_of_edges: 106692\n",
      "loading column 0 with feature abs_degree_difference_test.csv\n",
      "loading column 1 with feature common_elements_in_abstracts_test.csv\n",
      "loading column 2 with feature difference_of_abstracts_test.csv\n",
      "loading column 3 with feature doc2vec_test.csv\n",
      "loading column 4 with feature Graph_degree_sum_test.csv\n",
      "loading column 5 with feature sum_of_abstracts_len_test.csv\n",
      "loading column 6 with feature word2vec_test.csv\n",
      "Features created.\n"
     ]
    }
   ],
   "source": [
    "# Features :\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "# (4) sum of degrees of graph nodes\n",
    "# (5) absolute value of degrees of graph nodes\n",
    "# (6) Check if an author that exists in the left node's abstract , also exists in the right node's authors list.\n",
    "# (7) Cosine similarity between two abstracts\n",
    "# (8) sum of Author graph degrees\n",
    "# (9) absolute value of difference of author graph degrees.\n",
    "# (10) sum of Hubs from HITS algorithm\n",
    "# (11) sum of Authorities from HITS algorithm\n",
    "# (12) sum of pagerank ranks\n",
    "# (13) absolute value of difference of pagerank ranks\n",
    "# (14) sum of clustering algorithm nodes\n",
    "# (15) absolute value of difference of clustering algorithm nodes\n",
    "# (16) sum of average neighbor degrees\n",
    "# (17) absolute value of difference of average neighbor degrees\n",
    "# (18) sum of Degree centrality values\n",
    "# (19) absolute value of difference of degree centrality values\n",
    "# (20) sum of betweeness centrality values\n",
    "# (21) absolute value of difference of betweeness centrality values\n",
    "\n",
    "\n",
    "# X_train creation\n",
    "\n",
    "mypath='datasets/features_train/'\n",
    "X_train = initialize_x_train(m,get_feature_files(mypath),mypath)\n",
    "\n",
    "# Y_Train creation\n",
    "\n",
    "y_train = np.genfromtxt('datasets/Y_train.csv',delimiter=',')\n",
    "\n",
    "# shuffle elements\n",
    "\n",
    "X_train_m,y_train_m=shuffle(X_train,y_train)\n",
    "\n",
    "# X_test creation\n",
    "\n",
    "node_pairs = list()\n",
    "\n",
    "with open('datasets/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "mypath = 'datasets/features_test/'\n",
    "X_test = initialize_x_test(len(node_pairs),get_feature_files(mypath),mypath)\n",
    "\n",
    "print(\"Features created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd848c",
   "metadata": {},
   "source": [
    "## Logistic Regression model\n",
    "### this cell runs the LR model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee39ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Testing Logistic Regression model\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear',C=10.0,random_state=0)\n",
    "\n",
    "model = lr.fit(X_train_m,y_train_m)\n",
    "\n",
    "print(\"Model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da129c8",
   "metadata": {},
   "source": [
    "## HIST Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134d8752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIST Gradient booster complete.\n"
     ]
    }
   ],
   "source": [
    "# Testing HIST Gradient booster\n",
    "\n",
    "HISTmodel = HistGradientBoostingClassifier().fit(X_train, y_train)\n",
    "                                        \n",
    "hist_pred = HISTmodel.predict_proba(X_test)\n",
    "hist_pred = hist_pred[:,1]\n",
    "\n",
    "# RF CSV Creation\n",
    "predictions = zip(range(len(hist_pred)), hist_pred)\n",
    "with open(\"submission_HIST_csv.csv\",\"w\" , newline = '') as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n",
    "\n",
    "print(\"HIST Gradient booster complete.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50edc5",
   "metadata": {},
   "source": [
    "## Feature arrays for saving \n",
    "### this cell is used to create fake X_train , X_test in order to obtain csv files for features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527b03d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n",
      "Test done.\n",
      "Model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "authorNodeCount = authorGraph.number_of_nodes()\n",
    "\n",
    "# Jaccard coefficient\n",
    "\n",
    "#jc = list(nx.jaccard_coefficient(Graph))\n",
    "#print(jc[2])\n",
    "\n",
    "# HITS algorithm\n",
    "\n",
    "\n",
    "hubs, authorities = nx.hits(Graph, max_iter = 50, normalized = True)\n",
    "authHubs, authAuthorities = nx.hits(authorGraph , max_iter = 50 , normalized = True)\n",
    "\n",
    "#print(\"Hub Scores: \", hubs)\n",
    "#print(\"Authority Scores: \", authorities)\n",
    "\n",
    "#PageRank algorithm\n",
    "\n",
    "pr = nx.pagerank(Graph, alpha=0.9)\n",
    "\n",
    "# CLustering algorithm\n",
    "\n",
    "clusterDict = nx.clustering(Graph)\n",
    "\n",
    "# Average neighbor degree\n",
    "ANDdict = nx.average_neighbor_degree(Graph)\n",
    "\n",
    "# common neighbor centrality\n",
    "#cncDict = nx.common_neighbor_centrality(Graph)\n",
    "#print(cncDict[0])\n",
    "\n",
    "# degree centrality\n",
    "DCDict = nx.degree_centrality(Graph)\n",
    "\n",
    "# betweeness centrality\n",
    "#BC = nx.betweenness_centrality(Graph)\n",
    "\n",
    "# edge betweeness centrality\n",
    "#EBC = nx.edge_betweenness_centrality(Graph)\n",
    "\n",
    "# eigenvector centrality\n",
    "#ECDict = nx.eigenvector_centrality(Graph)\n",
    "\n",
    "# Shortest path\n",
    "#sp = nx.shortest_path(Graph)\n",
    "\n",
    "# katz centrality\n",
    "#katz = nx.katz_centrality(Graph)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    # CBOW testing\n",
    "    #abslist0 = list(abstracts[edge[0]])\n",
    "    #abslist1 = list(abstracts[edge[1]])\n",
    "    \n",
    "    if len(abstracts[edge[0]]) == 0 or len(abstracts[edge[1]]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #model1 = Word2Vec(abstracts[edge[0]], min_count = 1,vector_size = 10)\n",
    "        sim = model1.wv.n_similarity(abstracts[edge[0]],abstracts[edge[1]])\n",
    "\n",
    "    simContainer.append(sim)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    \n",
    "    # CBOW testing\n",
    "    \"\"\"\n",
    "    if len(abstracts[edge[0]]) == 0 or len(abstracts[edge[1]]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #model1 = Word2Vec(abstracts[edge[0]], min_count = 1,vector_size = 10)\n",
    "        sim = model1.wv.n_similarity(abstracts[edge[0]],abstracts[edge[1]])\n",
    "    \"\"\"\n",
    "    \n",
    "    # an edge\n",
    "    X_train[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    X_train[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    X_train[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    X_train[i,3] = Graph.degree[edge[0]] + Graph.degree[edge[1]]\n",
    "    X_train[i,4] = abs(Graph.degree[edge[0]] - Graph.degree[edge[1]])\n",
    "    X_train[i,5] = len(authors[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    X_train[i,6] = authorDeg[i,0] + authorDeg[i,1]\n",
    "    X_train[i,7] = abs(authorDeg[i,0] - authorDeg[i,1])\n",
    "    X_train[i,8] = hubs[edge[0]] + hubs[edge[1]]\n",
    "    X_train[i,9] = authorities[edge[0]] + authorities[edge[1]]\n",
    "    X_train[i,10] = pr[edge[0]] + pr[edge[1]]\n",
    "    X_train[i,11] = abs(pr[edge[0]] - pr[edge[1]])\n",
    "    X_train[i,12] = clusterDict[edge[0]] + clusterDict[edge[1]]\n",
    "    X_train[i,13] = abs(clusterDict[edge[0]] - clusterDict[edge[1]])\n",
    "    X_train[i,14] = ANDdict[edge[0]] + ANDdict[edge[1]]\n",
    "    X_train[i,15] = abs(ANDdict[edge[0]] - ANDdict[edge[1]])\n",
    "    X_train[i,16] = DCDict[edge[0]] + DCDict[edge[1]]\n",
    "    X_train[i,17] = abs(DCDict[edge[0]] - DCDict[edge[1]])\n",
    "    #X_train[i,18] = sp[edge[0]] + sp[edge[1]]\n",
    "    #X_train[i,19] = abs(sp[edge[0]] - sp[edge[1]])\n",
    "    #X_train[i,18] = BC[edge[0]] + BC[edge[1]]\n",
    "    #X_train[i,19] = abs(BC[edge[0]] - BC[edge[1]])\n",
    "    #X_train[i,20] =  #katz[edge[0]] + katz[edge[1]]\n",
    "    #X_train[i,21] = #abs(katz[edge[0]] - katz[edge[1]])\n",
    "    \n",
    "    \n",
    "    #X_train[i,10] = authHubs[edge[0]] + authHubs[edge[1]]\n",
    "    #X_train[i,11] = authAuthorities[edge[0]] + authAuthorities[edge[1]]\n",
    "    #X_train[i,10] = abs((hubs[edge[0]] + authorities[edge[0]]) - (hubs[edge[1]] + authorities[edge[1]])) \n",
    "    #X_train[i,10] = hubs[edge[0]] + authorities[edge[1]] #abs(hubs[edge[0]] - hubs[edge[1]])\n",
    "    #X_train[i,11] = abs(hubs[edge[0]] - authorities[edge[1]]) #abs(authorities[edge[0]] - authorities[edge[1]])\n",
    "    \n",
    "    #X_train[i,6] = sim\n",
    "    \n",
    "    y_train[i] = 1\n",
    "\n",
    "\n",
    "for i,edge in enumerate(Graph.edges()):\n",
    "    # a randomly generated pair of nodes\n",
    "    \n",
    "    n1 = rand.randint(0, nodeCount-1)\n",
    "    n2 = rand.randint(0, nodeCount-1)\n",
    "    \"\"\"\n",
    "    randabslist0 = list(abstracts[n1])\n",
    "    randabslist1 = list(abstracts[n2])\n",
    "    if len(abstracts[n1]) == 0 or len(abstracts[n2]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #model2 = gensim.models.Word2Vec(abstracts[n1], min_count = 1,vector_size = 100, window = 5)\n",
    "        sim2 = model1.wv.n_similarity(abstracts[n1],abstracts[n2])\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    X_train[m+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    X_train[m+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    X_train[m+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    X_train[m+i,3] = Graph.degree[n1] + Graph.degree[n2]\n",
    "    X_train[m+i,4] = abs(Graph.degree[n1] - Graph.degree[n2])\n",
    "    X_train[m+i,5] = len(authors[n1].intersection(abstracts[n2]))\n",
    "    X_train[m+i,6] = authorDeg[n1,0] + authorDeg[n2,1]\n",
    "    X_train[m+i,7] = abs(authorDeg[n1,0] - authorDeg[n2,1])\n",
    "    X_train[m+i,8] = hubs[n1] + hubs[n2]\n",
    "    X_train[m+i,9] = authorities[n1] + authorities[n2]\n",
    "    X_train[m+i,10] = pr[n1] + pr[n2]\n",
    "    X_train[m+i,11] = abs(pr[n1] - pr[n2])\n",
    "    X_train[m+i,12] = clusterDict[n1] + clusterDict[n2]\n",
    "    X_train[m+i,13] = abs(clusterDict[n1] - clusterDict[n2])\n",
    "    X_train[m+i,14] = ANDdict[n1] + ANDdict[n2]\n",
    "    X_train[m+i,15] = abs(ANDdict[n1] - ANDdict[n2])\n",
    "    X_train[m+i,16] = DCDict[n1] + DCDict[n2]\n",
    "    X_train[m+i,17] = abs(DCDict[n1] - DCDict[n2])\n",
    "    #X_train[m+i,18] = sp[n1] + sp[n2]\n",
    "    #X_train[m+i,19] = abs(sp[n1] - sp[n2])\n",
    "    #X_train[m+i,18] = BC[n1] + BC[n2] #ECDict[n1] + ECDict[n2]\n",
    "    #X_train[m+i,19] = abs(BC[n1] - BC[n2])#abs(ECDict[n1] - ECDict[n2])\n",
    "    #X_train[m+i,20] = #katz[n1] + katz[n2]\n",
    "   # X_train[m+i,21] = #abs(katz[n1] - katz[n2])\n",
    "    \n",
    "    \n",
    "    #X_train[m+i,10] = authHubs[n1] + authHubs[n2]\n",
    "    #X_train[m+i,11] = authAuthorities[n1] + authAuthorities[n2]\n",
    "    #X_train[m+1,10] = abs((hubs[n1] + authorities[n1]) - (hubs[n2] + authorities[n2])) \n",
    "    #X_train[m+i,10] = hubs[n1] + authorities[n2] #abs(hubs[n1] - hubs[n2])\n",
    "    #X_train[m+i,11] = abs(hubs[n1] - authorities[n2]) #abs(authorities[n1] - authorities[n2])\n",
    "    #X_train[m+i,6] = sim2\n",
    "    \n",
    "    y_train[m+i] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Training done.\")\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "for i,edge in enumerate(authorGraph.edges()):\n",
    "    # a randomly generated pair of nodes\n",
    "    \n",
    "    n1 = rand.randint(0, authorNodeCount-1)\n",
    "    n2 = rand.randint(0, authorNodeCount-1)\n",
    "    \n",
    "    X_train[m+i,6] = authorGraph.degree[n1] + authorGraph.degree[n2]\n",
    "    X_train[m+i,7] = abs(authorGraph.degree[n1] - authorGraph.degree[n2])\n",
    "\"\"\"    \n",
    "\n",
    "# print(degreeArr[abstracts.get(edge[0])])\n",
    "# 276998 <- 2 * number of nodes\n",
    "# 221598 80% training data\n",
    "# 55400 20% testing data\n",
    "        \n",
    "        \n",
    "# use test pairs as X_test data\n",
    "\n",
    "node_pairs = list()\n",
    "\n",
    "with open('datasets/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "        \n",
    "\n",
    "X_test = np.zeros((len(node_pairs), n))\n",
    "\n",
    "for i,node_pair in enumerate(node_pairs):\n",
    "    \"\"\"\n",
    "    pairAbsList0 = list(abstracts[node_pair[0]])\n",
    "    pairAbsList1 = list(abstracts[node_pair[1]])\n",
    "    \n",
    "    if len(abstracts[node_pair[0]]) == 0 or len(abstracts[node_pair[1]]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #model3 = gensim.models.Word2Vec(pairAbsList0, min_count = 1,vector_size = 100, window = 5)\n",
    "        sim3 = model3.wv.n_similarity(abstracts[node_pair[0]],abstracts[node_pair[1]])\n",
    "    \"\"\"\n",
    "    \n",
    "    X_test[i,0] = len(abstracts[node_pair[0]]) + len(abstracts[node_pair[1]])\n",
    "    X_test[i,1] = abs(len(abstracts[node_pair[0]]) - len(abstracts[node_pair[1]]))\n",
    "    X_test[i,2] = len(abstracts[node_pair[0]].intersection(abstracts[node_pair[1]]))\n",
    "    X_test[i,3] = Graph.degree[node_pair[0]] + Graph.degree[node_pair[1]]\n",
    "    X_test[i,4] = abs(Graph.degree[node_pair[0]] - Graph.degree[node_pair[1]])\n",
    "    X_test[i,5] = len(authors[node_pair[0]].intersection(abstracts[node_pair[1]]))\n",
    "    X_test[i,6] = authorDeg[node_pair[0],0] + authorDeg[node_pair[1],1]\n",
    "    X_test[i,7] = abs(authorDeg[node_pair[0],0] - authorDeg[node_pair[1],1])\n",
    "    X_test[i,8] = hubs[node_pair[0]] + hubs[node_pair[1]]\n",
    "    X_test[i,9] = authorities[node_pair[0]] + authorities[node_pair[1]]\n",
    "    X_test[i,10] = pr[node_pair[0]] + pr[node_pair[1]]\n",
    "    X_test[i,11] = abs(pr[node_pair[0]] - pr[node_pair[1]])\n",
    "    X_test[i,12] = clusterDict[node_pair[0]] + clusterDict[node_pair[1]]\n",
    "    X_test[i,13] = abs(clusterDict[node_pair[0]] - clusterDict[node_pair[1]])\n",
    "    X_test[i,14] = ANDdict[node_pair[0]] + ANDdict[node_pair[1]]\n",
    "    X_test[i,15] = abs(ANDdict[node_pair[0]] - ANDdict[node_pair[1]])\n",
    "    X_test[i,16] = DCDict[node_pair[0]] + DCDict[node_pair[1]]\n",
    "    X_test[i,17] = abs(DCDict[node_pair[0]] - DCDict[node_pair[1]])\n",
    "    #X_test[i,18] = sp[node_pair[0]] + sp[node_pair[1]]\n",
    "    #X_test[i,19] = abs(sp[node_pair[0]] - sp[node_pair[1]])\n",
    "    #X_test[i,18] = BC[node_pair[0]]  + BC[node_pair[1]] #ECDict[node_pair[0]] + ECDict[node_pair[1]]\n",
    "    #X_test[i,19] = abs(BC[node_pair[0]] - BC[node_pair[1]]) #abs(ECDict[node_pair[0]] - ECDict[node_pair[1]])\n",
    "    #X_test[i,20] = #katz[node_pair[0]] + katz[node_pair[1]]\n",
    "    #X_test[i,21] = #abs(katz[node_pair[0]] - katz[node_pair[1]])\n",
    "    \n",
    "    #X_train[i,10] = authHubs[node_pair[0]] + authHubs[node_pair[1]]\n",
    "    #X_train[i,11] = authAuthorities[node_pair[0]] + authAuthorities[node_pair[1]]\n",
    "    #X_test[i,10] = abs((hubs[node_pair[0]] + authorities[node_pair[0]]) - (hubs[node_pair[1]] + authorities[node_pair[1]])) \n",
    "    #X_test[i,10] = hubs[node_pair[0]] + authorities[node_pair[1]]#abs(hubs[node_pair[0]] - hubs[node_pair[1]])\n",
    "    #X_test[i,11] = abs(hubs[node_pair[0]] - authorities[node_pair[1]])#abs(authorities[node_pair[0]] - authorities[node_pair[1]])\n",
    "    #X_test[i,6] = sim3 abs((hubs[edge[0]] + authorities[edge[0]]) - (hubs[edge[1]] + authorities[edge[1]])) \n",
    "    \n",
    "    \n",
    "print(\"Test done.\")\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "for i,edge in enumerate(authorGraph.edges()):\n",
    "    X_test[i,6] = authorGraph.degree[node_pair[0]] + authorGraph.degree[node_pair[1]]\n",
    "    X_test[i,7] = abs(authorGraph.degree[node_pair[0]] - authorGraph.degree[node_pair[1]]) \n",
    "\"\"\"   \n",
    "\n",
    "# shuffle train data\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "# Testing Logistic Regression model\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear',C=10.0,random_state=0)\n",
    "\n",
    "model = lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"Model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cfc73f",
   "metadata": {},
   "source": [
    "## Feature saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539805ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features saved.\n",
      "Test features saved.\n"
     ]
    }
   ],
   "source": [
    "# Feature saving\n",
    "# Train features\n",
    "\n",
    "savetxt('datasets/features_train/Graph_degree_sum.csv',X_train[:,3],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_degree_difference.csv',X_train[:,4],delimiter=',')\n",
    "savetxt('datasets/features_train/len_of_intersection_authors_abstracts.csv',X_train[:,5],delimiter=',')\n",
    "savetxt('datasets/features_train/author_graph_degrees.csv',X_train[:,6],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_difference_of_author_graph_degrees.csv',X_train[:,7],delimiter=',')\n",
    "savetxt('datasets/features_train/hubs_sum.csv',X_train[:,8],delimiter=',')\n",
    "savetxt('datasets/features_train/authorities_sum.csv',X_train[:,9],delimiter=',')\n",
    "savetxt('datasets/features_train/pagerank_sum.csv',X_train[:,10],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_diff_pagerank.csv',X_train[:,11],delimiter=',')\n",
    "savetxt('datasets/features_train/clustering_sum.csv',X_train[:,12],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_diff_clustering.csv',X_train[:,13],delimiter=',')\n",
    "savetxt('datasets/features_train/average_neighbor_degree.csv',X_train[:,14],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_diff_average_neighbor_degree.csv',X_train[:,15],delimiter=',')\n",
    "savetxt('datasets/features_train/degree_centrality.csv',X_train[:,16],delimiter=',')\n",
    "savetxt('datasets/features_train/abs_diff_degree_centrality.csv',X_train[:,17],delimiter=',')\n",
    "\n",
    "print(\"Training features saved.\")\n",
    "\n",
    "# Test features\n",
    "\n",
    "savetxt('datasets/features_test/Graph_degree__sum_test.csv',X_test[:,3],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_degree_difference_test.csv',X_test[:,4],delimiter=',')\n",
    "savetxt('datasets/features_test/len_of_intersection_authors_abstracts_test.csv',X_test[:,5],delimiter=',')\n",
    "savetxt('datasets/features_test/author_graph_degrees_test.csv',X_test[:,6],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_difference_of_author_graph_degrees_test.csv',X_test[:,7],delimiter=',')\n",
    "savetxt('datasets/features_test/hubs_sum_test.csv',X_test[:,8],delimiter=',')\n",
    "savetxt('datasets/features_test/authorities_sum_test.csv',X_test[:,9],delimiter=',')\n",
    "savetxt('datasets/features_test/pagerank_sum_test.csv',X_test[:,10],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_diff_pagerank_test.csv',X_test[:,11],delimiter=',')\n",
    "savetxt('datasets/features_test/clustering_sum_test.csv',X_test[:,12],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_diff_clustering_test.csv',X_test[:,13],delimiter=',')\n",
    "savetxt('datasets/features_test/average_neighbor_degree_test.csv',X_test[:,14],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_diff_average_neighbor_degree_test.csv',X_test[:,15],delimiter=',')\n",
    "savetxt('datasets/features_test/degree_centrality_test.csv',X_test[:,16],delimiter=',')\n",
    "savetxt('datasets/features_test/abs_diff_degree_centrality_test.csv',X_test[:,17],delimiter=',')\n",
    "\n",
    "print(\"Test features saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2d6bd",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd39397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106692, 2)\n",
      "0.9800480186183853\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier model\n",
    "# at this point best NB is the Categorical one with 0.52 log loss\n",
    "\n",
    "NB = CategoricalNB()\n",
    "NBmodel = NB.fit(X_train,y_train)\n",
    "\n",
    "nby_pred = NBmodel.predict_proba(X_test)\n",
    "#for i in range(0,10):\n",
    "   # print(nby_pred)\n",
    "print(nby_pred.shape)\n",
    "nby_pred = nby_pred[:,1]\n",
    "\n",
    "# NB CSV creation\n",
    "\n",
    "predictions = zip(range(len(nby_pred)), nby_pred)\n",
    "with open(\"submission_NB_csv.csv\",\"w\" , newline = '') as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "\n",
    "binarray = np.zeros(len(X_test))\n",
    "mean = np.mean(X_test)\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    meanTuple = np.mean(X_test[i])\n",
    "    if meanTuple > mean:\n",
    "        binarray[i] = 1\n",
    "    else:\n",
    "        binarray[i] = 0\n",
    "        \n",
    "print(log_loss(binarray,nby_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe8b06",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abf69abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest complete.\n"
     ]
    }
   ],
   "source": [
    "# 51 % log loss\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RFmodel = RF.fit(X_train,y_train)\n",
    "\n",
    "rf_pred = RFmodel.predict_proba(X_test)\n",
    "rf_pred = rf_pred[:,1]\n",
    "\n",
    "# RF CSV Creation\n",
    "predictions = zip(range(len(rf_pred)), rf_pred)\n",
    "with open(\"submission_RF_csv.csv\",\"w\" , newline = '') as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n",
    "\n",
    "print(\"Random Forest complete.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870af6d7",
   "metadata": {},
   "source": [
    "## Testing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "572731cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "wordList = ()\n",
    "\n",
    "abstracts1 = dict()\n",
    "with open('datasets/abstracts.txt', 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        node, abstract = line.split('|--|')\n",
    "        abstracts1[int(node)] = abstract\n",
    "\n",
    "#for node in abstracts1:\n",
    "    #abstracts1[node] = set(abstracts1[node].split()) \n",
    "\n",
    "# word frequency\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "string = abstracts1[3]\n",
    "str_list = string.split()\n",
    "unique_words = set(str_list)\n",
    "\n",
    "for word in unique_words:\n",
    "    if len(word) >= 3 and len(word) <= 6:\n",
    "        continue\n",
    "        #print(word)\n",
    "\n",
    "# 3 , 2214\n",
    "# 11042 11239\n",
    "\n",
    "#for word in unique_words:\n",
    "    #print('Frequency of ', word , 'is :', str_list.count(word))\n",
    "        \n",
    "#print(abstracts1[3]) \n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "for word in string:\n",
    "    str_list = word.split()\n",
    "\n",
    "unique_words = set(str_list)\n",
    "\n",
    "for word in unique_words:\n",
    "    print('Frequency of ', word , 'is :', str_list.count(word))\n",
    "\"\"\"\n",
    "\n",
    "#for i in range(0,10):\n",
    "    #print(X_test[i][6])\n",
    "\n",
    "for i,edge in enumerate(authorGraph.edges()):\n",
    "    if i > 3:\n",
    "        break\n",
    "    print(authorGraph.degree[edge[0]])\n",
    "    \n",
    "#print(abstracts[134761])\n",
    "#for word in authors[2559]:\n",
    "   # word = word.split()\n",
    "   # print(word)\n",
    "#abslist = list(abstracts[0])\n",
    "\n",
    "#print(abstracts[0])\n",
    "#sim5 = model1.wv.most_similar(absSet[1])\n",
    "#print(sim5)\n",
    "#print(authors[2559])\n",
    "#result = abstracts1[134761].intersection(authors[2559])\n",
    "#print(result)\n",
    "\n",
    "# prwta 5 stoixeia tou CSV\n",
    "# 0\t0.976707924\n",
    "# 1\t0.144358737\n",
    "# 2\t0.957898003\n",
    "# 3\t0.192365151\n",
    "# 4\t0.245021383\n",
    "# 5\t0.775259045\n",
    "\n",
    "# 1. vriskoume frequency olwn twn lexewn\n",
    "# 2. svhnoume oses einai >= \n",
    "# 3. se kathe abstract pairnoume \n",
    "\n",
    "\n",
    "# CBOW test with least frequent words\n",
    "#print(abstracts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e663dd7",
   "metadata": {},
   "source": [
    "## CSV creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcdee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV successfully created.\n"
     ]
    }
   ],
   "source": [
    "# predict citation\n",
    "\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "# create csv\n",
    "\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission_csv.csv\",\"w\" , newline = '') as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "print(\"CSV successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902eb95d",
   "metadata": {},
   "source": [
    "## local Log Loss Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8685745",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0342340848104377\n"
     ]
    }
   ],
   "source": [
    "# Log loss computation\n",
    "\n",
    "\n",
    "#binarray = np.zeros((len(X_test),n))\n",
    "binarray = np.zeros(len(X_test))\n",
    "mean = np.mean(X_test)\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    meanTuple = np.mean(X_test[i])\n",
    "    if meanTuple > mean:\n",
    "        binarray[i] = 1\n",
    "    else:\n",
    "        binarray[i] = 0\n",
    "        \n",
    "print(log_loss(binarray,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
