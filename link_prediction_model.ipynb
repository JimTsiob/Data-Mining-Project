{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bd7e7b",
   "metadata": {},
   "source": [
    "# Link prediction project for paper citations\n",
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7d9cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import random as rand\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4f6f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodes  edges\n",
      "0      0      1\n",
      "1      0      2\n",
      "2      1      3\n",
      "3      1      5\n",
      "4      1      6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "dataset = pd.read_csv('datasets/edgelist.txt', sep = ',' ,header = None)\n",
    "\n",
    "\n",
    "# add names to columns for easier manipulation of data\n",
    "dataset.columns = ['nodes','edges']\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "# check for nan values\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d514723",
   "metadata": {},
   "source": [
    "### Graph creation and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65846895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Graph = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "\n",
    "for x in dataset['nodes']:\n",
    "    Graph.add_node(x)\n",
    "\n",
    "# add edges\n",
    "\n",
    "for x,y in dataset.itertuples(index = False):\n",
    "    Graph.add_edge(x,y)\n",
    "    \n",
    "    \n",
    "print(len(Graph.nodes))\n",
    "\n",
    "# creation of sub graph for plotting \n",
    "\n",
    "subset_data = pd.DataFrame(columns = ['nodes','edges'])\n",
    "\n",
    "subset_data = dataset.head(10000)\n",
    "\n",
    "subG = nx.Graph()\n",
    "print(len(subset_data))\n",
    "for x in subset_data['nodes']:\n",
    "    subG.add_node(x)\n",
    "    \n",
    "for x,y in subset_data.itertuples(index = False):\n",
    "    subG.add_edge(x,y)\n",
    "    \n",
    "# plot graph\n",
    "\n",
    "nx.draw(subG)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50edc5",
   "metadata": {},
   "source": [
    "### Feature Extraction , model creation and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "527b03d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "(1747128, 3)\n",
      "(1747128,)\n",
      "(436782, 3)\n",
      "(436782, 2)\n",
      "[1.00000000e+00 4.68186842e-16]\n",
      "[1.00000000e+00 4.56582987e-16]\n",
      "[1.00000000e+00 4.66146976e-16]\n",
      "[1.00000000e+00 4.75806708e-16]\n",
      "[1.66533454e-14 1.00000000e+00]\n",
      "[1.66533454e-14 1.00000000e+00]\n",
      "[1.73194792e-14 1.00000000e+00]\n",
      "[1.00000000e+00 4.64699287e-16]\n",
      "[1.00000000e+00 4.55814237e-16]\n",
      "[2.6423308e-14 1.0000000e+00]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24668/2638931544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# create csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "# train test split (80% train data , 20% test data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = Graph.number_of_edges()\n",
    "n = 3\n",
    "\n",
    "X = np.zeros((2*m,n))\n",
    "y = np.zeros(2*m)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,m):\n",
    "    X[i,0] = Graph.degree[dataset['nodes'][i]] # degree of first node\n",
    "    X[i,1] = Graph.degree[dataset['edges'][i]] # degree of second node\n",
    "    X[i,2] = X[i,0] + X[i,1] # sum of these degrees\n",
    "\n",
    "\n",
    "for i in range(m,2*m): # we take all unconnected pairs for negative sample \n",
    "    X[i,0] = 138499 - X[i-m,0] # Graph.degree[dataset['nodes'][rand.randint(0,m-1)]]\n",
    "    X[i,1] = 138499 - X[i-m,1] # Graph.degree[dataset['edges'][rand.randint(0,m-1)]]\n",
    "    X[i,2] = X[i,0] + X[i,1]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# 276998 <- 2 * number of nodes\n",
    "# 221598 80% training data\n",
    "# 55400 20% testing data\n",
    "    \n",
    "    \n",
    "for i in range(0,m):\n",
    "    y[i] = 1 # positive sample\n",
    "    \n",
    "for i in range(m,2*m):\n",
    "    y[i] = 0 # negative sample\n",
    "\n",
    "\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(ytest[i])\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "\n",
    "# Testing Logistic Regression model\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870af6d7",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "572731cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.058656011955534e-15\n"
     ]
    }
   ],
   "source": [
    "# Log loss computation\n",
    "\n",
    "print(log_loss(ytest,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e663dd7",
   "metadata": {},
   "source": [
    "## CSV creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ddcdee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436782, 2)\n",
      "[1.00000000e+00 4.68186842e-16]\n",
      "[1.00000000e+00 4.56582987e-16]\n",
      "[1.00000000e+00 4.66146976e-16]\n",
      "[1.00000000e+00 4.75806708e-16]\n",
      "[1.66533454e-14 1.00000000e+00]\n",
      "[1.66533454e-14 1.00000000e+00]\n",
      "[1.73194792e-14 1.00000000e+00]\n",
      "[1.00000000e+00 4.64699287e-16]\n",
      "[1.00000000e+00 4.55814237e-16]\n",
      "[2.6423308e-14 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# predict citation\n",
    "\n",
    "predictions = model.predict_proba(xtest)\n",
    "print(predictions.shape)\n",
    "for i in range(0,10):\n",
    "    print(predictions[i])\n",
    "\n",
    "# numpy array that will hold the final results\n",
    "\n",
    "final = np.zeros((106692,2))\n",
    "\n",
    "for i in range(0,106692):\n",
    "    final[i][0] = i\n",
    "    final[i][1] = predictions[i][0]\n",
    "\n",
    "# create csv\n",
    "\n",
    "f = open('submission_csv.csv', 'w' , newline = '')\n",
    "\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for i in range(0,106692):\n",
    "    writer.writerow(final[i])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea9ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
