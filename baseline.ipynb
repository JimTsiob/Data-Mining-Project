{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "source": [
    "G=nx.read_edgelist('datasets/edgelist.txt', delimiter=',',create_using=nx.Graph(),nodetype=int)\n",
    "nodes=list(G.nodes())\n",
    "n=G.number_of_nodes()\n",
    "m=G.number_of_edges()\n",
    "\n",
    "print('Number of nodes:', n)\n",
    "\n",
    "print('Number of edges:', m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts=dict()\n",
    "with open('datasets/abstracts.txt', 'r',encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        node,abstract=line.split('|--|')\n",
    "        abstracts[int(node)]=abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in abstracts:\n",
    "    abstracts[node]=set(abstracts[node].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.zeros((2*m,3))\n",
    "y_train=np.zeros(2*m)\n",
    "n=G.number_of_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(0, 1)\n",
      "1\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "#i==a counter starting from zero,\n",
    "#edge==the edge associated with that node\n",
    "#one iteration returns G.edges(0)\n",
    "#i=0, edge=0,1\n",
    "#i=1, edge=0,2\n",
    "\n",
    "for i,edge in enumerate(G.edges(0)):\n",
    "    print(i)\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.zeros((2*m,3))\n",
    "y_train=np.zeros(2*m)\n",
    "n=G.number_of_nodes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and', 'luminaire,', 'This', 'record', 'grey', 'methodology', 'then', 'assessment', 'Experiments', 'descent', 'normal', 'a', 'are', 'placed', 'pattern', 'aircraft', 'match', 'luminous', 'level', 'brightness', 'calculate', 'during', 'aerodrome', 'was', 'quality', 'cockpit', 'value', 'used', 'As', 'optimum', 'The', 'on', 'determined.', 'metric', 'compared', 'standards', 'system.', 'inside', 'the', 'to', 'model-based', 'along', 'ground', 'pixel', 'luminaire', 'with', 'be', 'is', 'between', 'ascertain', 'data', 'intensity', 'such,', 'development', 'images', 'demonstrate', 'each', 'associated', 'sensor,', 'position', 'for', 'real', 'image', 'aerodrome.', 'composed', 'estimate', 'instant', 'system', 'expected', 'recommendations,', 'ensure', 'orientation', 'camera', 'actual', 'presented', 'imaged', 'order', 'of', 'required', 'operating', 'lighting', 'A', 'accordance', 'AGL', 'it', 'luminaire.', 'effectiveness', 'an', 'presented.', 'that', 'in', '(AGL),', 'application', 'automated', 'standards.', 'at', 'template', 'can', 'given', 'acquired.'}\n"
     ]
    }
   ],
   "source": [
    "edge=(0,1)\n",
    "print(abstracts[edge[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstracts[edge[0]] == the set of words in the abstract of \n",
    "#node A\n",
    "#abstracts[edge[1]]==the set of words in the abstract\n",
    "#of node B\n",
    "#nodes A,B are connected through edge edge\n",
    "\n",
    "for i,edge in enumerate(G.edges()):\n",
    "    X_train[i,0]=len(abstracts[edge[0]])+len(abstracts[edge[1]])\n",
    "    X_train[i,1]=len(abstracts[edge[1]])-len(abstracts[edge[1]])\n",
    "    X_train[i,2]=len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    y_train[i]=1\n",
    "\n",
    "    #randomly generate a pair of nodes\n",
    "    #we assume that these connections do not\n",
    "    # exist in the graph\n",
    "    X_train[m+i,0]=len(abstracts[edge[0]])+len(abstracts[edge[1]])\n",
    "    X_train[m+i,1]=len(abstracts[edge[0]])-len(abstracts[edge[1]])\n",
    "    X_train[m+i,2]=len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    y_train[m+i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training matrix= (2183910, 3)\n"
     ]
    }
   ],
   "source": [
    "print('size of training matrix=',X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pairs = list()\n",
    "with open('datasets/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        #the raw split form is ['12223', '345332\\n']\n",
    "        #we need to make them integers\n",
    "        #use the function int()\n",
    "        node_pairs.append((int(t[0]), int(t[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test matrix is:  (106692, 3)\n"
     ]
    }
   ],
   "source": [
    "#np.zeros needs the shape of the matrix as a tuple\n",
    "#create the test matrix with the same features as the training matrix\n",
    "\n",
    "X_test=np.zeros((len(node_pairs),3))\n",
    "for (i,edge) in enumerate(node_pairs):\n",
    "    X_test[i,0]=len(abstracts[edge[0]])+len(abstracts[edge[1]])\n",
    "    X_test[i,1]=len(abstracts[edge[0]])-len(abstracts[edge[1]])\n",
    "    X_test[i,2]=len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "\n",
    "print(\"size of test matrix is: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train our model\n",
    "#why use shuffle though?\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=LogisticRegression(solver='liblinear',random_state=34)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred=classifier.predict_proba(X_test)\n",
    "#predict_proba returns an array with the probs of \n",
    "#0 and 1 eg[0.34, 0.66]\n",
    "#we keep only the probabilities of there existing a node\n",
    "y_pred=y_pred[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=zip(range(len(y_pred)),y_pred)\n",
    "with open(\"datasets/submission_text_baseline.csv\", 'w') as pred:\n",
    "    csv_out=csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60d3da1ceb4a5c2d8db96e094ed8a441bc436ca9db84d9636bbf8f172da6bf94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('ml-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
